{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e58cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34275a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "hasattr(F, \"rms_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebb80ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'ReChorus'\n",
      "/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus\n"
     ]
    }
   ],
   "source": [
    "%cd ReChorus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bf500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/models_saved\"\n",
    "LOG_DIR = \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aeb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_ML1M_L200 = (\n",
    "    \"--dataset Grocery_and_Gourmet_Food --path data \"     # 或者你自己的 data 路径\n",
    "    \"--history_max 200 \"\n",
    "    \"--gpu 0 \"\n",
    "    \"--lr 1e-3 --l2 0 \"\n",
    "    \"--epoch 101 --early_stop 0 \"                     # early_stop 你可以照以前的 10\n",
    "    \"--batch_size 128 --eval_batch_size 128 \"\n",
    "    \"--num_neg 128 \"                                   # SampledSoftmax 的负样本数\n",
    "    \"--dropout 0.2 \"                                   # 对应 train_fn.dropout_rate\n",
    "    \"--metric NDCG,HR --topk 5,10,20,50 \"\n",
    "    \"--emb_size 50 \"                                   # item_embedding_dim\n",
    "    \"--fuxi_linear_activation silu \"\n",
    "    \"--fuxi_linear_dropout 0.2 --fuxi_attn_dropout 0.2 \"\n",
    "    \"--fuxi_ffn_multiply 1.0 --fuxi_ffn_single_stage 0 \"\n",
    "    \"--fuxi_enable_rel_bias 1 \"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 普通 FuXi (2 blocks, 1 head, dqk=dv=50)\n",
    "model_path = f\"{MODEL_DIR}/fuxi_upgrade_grocery_large.pt\"\n",
    "log_file   = f\"{LOG_DIR}/fuxi_upgrade_grocery_large.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce5560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/main.py:25: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"bool\"):\n",
      "Namespace(model_name='fuxi', model_mode='')\n",
      "--------------------------------------------- BEGIN: 2025-11-30 18:34:55 ---------------------------------------------\n",
      "\n",
      "===============================================\n",
      " Arguments              | Values               \n",
      "===============================================\n",
      " batch_size             | 128                 \n",
      " data_appendix          |                     \n",
      " dataset                | Grocery_and_Gourm...\n",
      " dropout                | 0.2                 \n",
      " early_stop             | 0                   \n",
      " emb_size               | 50                  \n",
      " epoch                  | 101                 \n",
      " eval_batch_size        | 128                 \n",
      " fuxi_attention_dim     | 25                  \n",
      " fuxi_attn_dropout      | 0.2                 \n",
      " fuxi_blocks            | 8                   \n",
      " fuxi_enable_rel_bias   | 1                   \n",
      " fuxi_ffn_multiply      | 1.0                 \n",
      " fuxi_ffn_single_stage  | 0                   \n",
      " fuxi_heads             | 2                   \n",
      " fuxi_linear_activation | silu                \n",
      " fuxi_linear_dim        | 25                  \n",
      " fuxi_linear_dropout    | 0.2                 \n",
      " gpu                    | 0                   \n",
      " history_max            | 200                 \n",
      " l2                     | 0.0                 \n",
      " lr                     | 0.001               \n",
      " main_metric            |                     \n",
      " num_neg                | 128                 \n",
      " num_workers            | 5                   \n",
      " optimizer              | Adam                \n",
      " random_seed            | 0                   \n",
      " save_final_results     | 0                   \n",
      " test_all               | 0                   \n",
      " topk                   | 5,10,20,50          \n",
      "===============================================\n",
      "Device: cuda\n",
      "Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl\n",
      "Initialize _item_emb.weight as truncated normal: torch.Size([8715, 50]) params\n",
      "#params: 690440\n",
      "FuXi(\n",
      "  (embedding_module): LocalEmbeddingModule(\n",
      "    (_item_emb): Embedding(8715, 50, padding_idx=0)\n",
      "  )\n",
      "  (interaction_module): DotProductSimilarity()\n",
      "  (input_preproc): LearnablePositionalEmbeddingInputFeaturesPreprocessor(\n",
      "    (_pos_emb): Embedding(201, 50)\n",
      "    (_emb_dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (output_postproc): L2NormEmbeddingPostprocessor()\n",
      "  (encoder): FuXi(\n",
      "    (_ndp_module): DotProductSimilarity()\n",
      "    (_embedding_module): LocalEmbeddingModule(\n",
      "      (_item_emb): Embedding(8715, 50, padding_idx=0)\n",
      "    )\n",
      "    (_input_features_preproc): LearnablePositionalEmbeddingInputFeaturesPreprocessor(\n",
      "      (_pos_emb): Embedding(201, 50)\n",
      "      (_emb_dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (_output_postproc): L2NormEmbeddingPostprocessor()\n",
      "    (_fuxi): FuXiJagged(\n",
      "      (_attention_layers): ModuleList(\n",
      "        (0-7): 8 x FuXiBlockJagged(\n",
      "          (_rel_attn_bias): SeperatedRelativeBucketedTimeAndPositionBasedBias()\n",
      "          (_mffn): MultistageFeedforwardNeuralNetwork(\n",
      "            (lin0): Linear(in_features=150, out_features=50, bias=True)\n",
      "            (lin1): Linear(in_features=50, out_features=50, bias=False)\n",
      "            (lin2): Linear(in_features=50, out_features=50, bias=False)\n",
      "            (lin3): Linear(in_features=50, out_features=50, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Traceback (most recent call last):                                                                  \n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/main.py\", line 209, in <module>\n",
      "    main()\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/main.py\", line 93, in main\n",
      "    logging.info('Test Before Training: ' + runner.print_res(data_dict['test']))\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/helpers/BaseRunner.py\", line 259, in print_res\n",
      "    result_dict = self.evaluate(dataset, self.topk, self.metrics)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/helpers/BaseRunner.py\", line 222, in evaluate\n",
      "    predictions = self.predict(dataset)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/helpers/BaseRunner.py\", line 240, in predict\n",
      "    prediction = dataset.model(utils.batch_to_gpu(batch, dataset.model.device))['prediction']\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 933, in forward\n",
      "    user_emb = self.encoder.encode(\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 816, in encode\n",
      "    return self._encode(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 777, in _encode\n",
      "    encoded_seq_embeddings, cache_states = self.generate_user_embeddings(\n",
      "                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 711, in generate_user_embeddings\n",
      "    user_embeddings, cached_states = self._fuxi(\n",
      "                                     ^^^^^^^^^^^\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 542, in forward\n",
      "    jagged_x, cache_states = self.jagged_forward(\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 506, in jagged_forward\n",
      "    x, cache_states_i = layer(\n",
      "                        ^^^^^^\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 424, in forward\n",
      "    attn_output, padded_q, padded_k = _adaptive_multichannel_attention_maybe_from_cache(\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 207, in _adaptive_multichannel_attention_maybe_from_cache\n",
      "    pos_attn, ts_attn = rel_attn_bias(all_timestamps)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 112, in forward\n",
      "    self._bucketization_fn(\n",
      "  File \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/sequential/fuxi.py\", line 625, in <lambda>\n",
      "    torch.log(torch.abs(x).clamp(min=1)) / 0.301\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 2.56 GiB is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 2.40 GiB is allocated by PyTorch, and 19.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "!python src/main.py $COMMON_ML1M_L200 \\\n",
    "  --model_name fuxi_upgrade \\\n",
    "  --model_path {model_path} \\\n",
    "  --log_file {log_file} \\\n",
    "  --fuxi_blocks  8\\\n",
    "  --fuxi_heads 2 \\\n",
    "  --fuxi_attention_dim 25 \\\n",
    "  --fuxi_linear_dim 25 \\\n",
    "  --save_final_results 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
