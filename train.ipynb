{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e58cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34275a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "hasattr(F, \"rms_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ebb80ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus\n"
     ]
    }
   ],
   "source": [
    "%cd ReChorus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38bf500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/models_saved\"\n",
    "LOG_DIR = \"/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aeb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_ML1M_L200 = (\n",
    "    \"--dataset Grocery_and_Gourmet_Food --path data \"     # 或者你自己的 data 路径\n",
    "    \"--history_max 200 \"\n",
    "    \"--gpu 0 \"\n",
    "    \"--lr 1e-3 --l2 0 \"\n",
    "    \"--epoch 101 --early_stop 0 \"                     # early_stop 你可以照以前的 10\n",
    "    \"--batch_size 128 --eval_batch_size 128 \"\n",
    "    \"--num_neg 128 \"                                   # SampledSoftmax 的负样本数\n",
    "    \"--dropout 0.2 \"                                   # 对应 train_fn.dropout_rate\n",
    "    \"--metric NDCG,HR --topk 5,10,20,50 \"\n",
    "    \"--emb_size 50 \"                                   # item_embedding_dim\n",
    "    \"--fuxi_linear_activation silu \"\n",
    "    \"--fuxi_linear_dropout 0.2 --fuxi_attn_dropout 0.2 \"\n",
    "    \"--fuxi_ffn_multiply 1.0 --fuxi_ffn_single_stage 0 \"\n",
    "    \"--fuxi_enable_rel_bias 1 \"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 普通 FuXi (2 blocks, 1 head, dqk=dv=50)\n",
    "model_path = f\"{MODEL_DIR}/fuxi_upgrade_grocery_large.pt\"\n",
    "log_file   = f\"{LOG_DIR}/fuxi_upgrade_grocery_large.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdce5560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/main.py:25: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"bool\"):\n",
      "Namespace(model_name='fuxi_upgrade', model_mode='')\n",
      "--------------------------------------------- BEGIN: 2025-12-02 11:50:23 ---------------------------------------------\n",
      "\n",
      "===============================================\n",
      " Arguments              | Values               \n",
      "===============================================\n",
      " batch_size             | 128                 \n",
      " data_appendix          |                     \n",
      " dataset                | Grocery_and_Gourm...\n",
      " dropout                | 0.2                 \n",
      " early_stop             | 0                   \n",
      " emb_size               | 50                  \n",
      " epoch                  | 101                 \n",
      " eval_batch_size        | 128                 \n",
      " fuxi_attention_dim     | 25                  \n",
      " fuxi_attn_dropout      | 0.2                 \n",
      " fuxi_blocks            | 8                   \n",
      " fuxi_enable_rel_bias   | 1                   \n",
      " fuxi_ffn_multiply      | 1.0                 \n",
      " fuxi_ffn_single_stage  | 0                   \n",
      " fuxi_heads             | 2                   \n",
      " fuxi_linear_activation | silu                \n",
      " fuxi_linear_dim        | 25                  \n",
      " fuxi_linear_dropout    | 0.2                 \n",
      " gpu                    | 0                   \n",
      " history_max            | 200                 \n",
      " l2                     | 0.0                 \n",
      " lr                     | 0.001               \n",
      " main_metric            |                     \n",
      " num_neg                | 128                 \n",
      " num_workers            | 5                   \n",
      " optimizer              | Adam                \n",
      " random_seed            | 0                   \n",
      " save_final_results     | 0                   \n",
      " test_all               | 0                   \n",
      " topk                   | 5,10,20,50          \n",
      "===============================================\n",
      "Device: cuda\n",
      "Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl\n",
      "Initialize _item_emb.weight as truncated normal: torch.Size([8715, 50]) params\n",
      "#params: 610440\n",
      "FuXiUpgrade(\n",
      "  (embedding_module): LocalEmbeddingModule(\n",
      "    (_item_emb): Embedding(8715, 50, padding_idx=0)\n",
      "  )\n",
      "  (interaction_module): DotProductSimilarity()\n",
      "  (input_preproc): LearnablePositionalEmbeddingInputFeaturesPreprocessor(\n",
      "    (_pos_emb): Embedding(201, 50)\n",
      "    (_emb_dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (output_postproc): L2NormEmbeddingPostprocessor()\n",
      "  (encoder): SemanticFreeFuXi(\n",
      "    (_ndp_module): DotProductSimilarity()\n",
      "    (_embedding_module): LocalEmbeddingModule(\n",
      "      (_item_emb): Embedding(8715, 50, padding_idx=0)\n",
      "    )\n",
      "    (_input_features_preproc): LearnablePositionalEmbeddingInputFeaturesPreprocessor(\n",
      "      (_pos_emb): Embedding(201, 50)\n",
      "      (_emb_dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (_output_postproc): L2NormEmbeddingPostprocessor()\n",
      "    (_fuxi): FuXiJagged(\n",
      "      (_attention_layers): ModuleList(\n",
      "        (0-7): 8 x SemanticFreeFuXiBlock(\n",
      "          (_rel_attn_bias): SeperatedRelativeBucketedTimeAndPositionBasedBias()\n",
      "          (_mffn): MultistageFeedforwardNeuralNetwork(\n",
      "            (lin0): Linear(in_features=100, out_features=50, bias=True)\n",
      "            (lin1): Linear(in_features=50, out_features=50, bias=False)\n",
      "            (lin2): Linear(in_features=50, out_features=50, bias=False)\n",
      "            (lin3): Linear(in_features=50, out_features=50, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Test Before Training: (HR@5:0.0507,NDCG@5:0.0295,HR@10:0.1036,NDCG@10:0.0464,HR@20:0.2071,NDCG@20:0.0722,HR@50:0.5053,NDCG@50:0.1303)\n",
      "Optimizer: Adam\n",
      "Epoch 1     loss=0.5998 [214.3 s]\tdev=(HR@5:0.2827,NDCG@5:0.1889) [13.9 s] *                        \n",
      "Epoch 2     loss=0.5176 [213.5 s]\tdev=(HR@5:0.3457,NDCG@5:0.2368) [13.3 s] *                        \n",
      "Epoch 3     loss=0.4882 [215.7 s]\tdev=(HR@5:0.3704,NDCG@5:0.2560) [14.4 s] *                        \n",
      "Epoch 4     loss=0.4676 [213.6 s]\tdev=(HR@5:0.3937,NDCG@5:0.2778) [14.4 s] *                        \n",
      "Epoch 5     loss=0.4492 [211.9 s]\tdev=(HR@5:0.4109,NDCG@5:0.2961) [12.8 s] *                        \n",
      "Epoch 6     loss=0.4306 [210.5 s]\tdev=(HR@5:0.4229,NDCG@5:0.3123) [14.0 s] *                        \n",
      "Epoch 7     loss=0.4135 [209.2 s]\tdev=(HR@5:0.4398,NDCG@5:0.3281) [13.1 s] *                        \n",
      "Epoch 8     loss=0.3987 [213.2 s]\tdev=(HR@5:0.4425,NDCG@5:0.3359) [17.4 s] *                        \n",
      "Epoch 9     loss=0.3865 [249.1 s]\tdev=(HR@5:0.4502,NDCG@5:0.3434) [19.1 s] *                        \n",
      "Epoch 10    loss=0.3764 [254.2 s]\tdev=(HR@5:0.4531,NDCG@5:0.3470) [13.1 s] *                        \n",
      "Epoch 11    loss=0.3675 [223.5 s]\tdev=(HR@5:0.4513,NDCG@5:0.3490) [14.6 s] *                        \n",
      "Epoch 12    loss=0.3593 [250.7 s]\tdev=(HR@5:0.4534,NDCG@5:0.3510) [16.8 s] *                        \n",
      "Epoch 13    loss=0.3525 [246.3 s]\tdev=(HR@5:0.4512,NDCG@5:0.3494) [15.7 s]                          \n",
      "Epoch 14    loss=0.3458 [236.4 s]\tdev=(HR@5:0.4549,NDCG@5:0.3539) [15.1 s] *                        \n",
      "Epoch 15    loss=0.3400 [252.4 s]\tdev=(HR@5:0.4529,NDCG@5:0.3523) [16.5 s]                          \n",
      "Epoch 16    loss=0.3341 [263.8 s]\tdev=(HR@5:0.4555,NDCG@5:0.3559) [14.1 s] *                        \n",
      "Epoch 17    loss=0.3290 [248.5 s]\tdev=(HR@5:0.4545,NDCG@5:0.3551) [15.8 s]                          \n",
      "Epoch 18    loss=0.3237 [250.4 s]\tdev=(HR@5:0.4556,NDCG@5:0.3559) [16.8 s]                          \n",
      "Epoch 19    loss=0.3190 [251.4 s]\tdev=(HR@5:0.4532,NDCG@5:0.3542) [15.4 s]                          \n",
      "Epoch 20    loss=0.3145 [249.0 s]\tdev=(HR@5:0.4560,NDCG@5:0.3565) [14.4 s] *                        \n",
      "Epoch 21    loss=0.3102 [254.0 s]\tdev=(HR@5:0.4546,NDCG@5:0.3568) [13.6 s] *                        \n",
      "Epoch 22    loss=0.3057 [236.1 s]\tdev=(HR@5:0.4521,NDCG@5:0.3545) [15.9 s]                          \n",
      "Epoch 23    loss=0.3017 [259.5 s]\tdev=(HR@5:0.4526,NDCG@5:0.3550) [18.1 s]                          \n",
      "Epoch 24    loss=0.2979 [250.7 s]\tdev=(HR@5:0.4518,NDCG@5:0.3543) [15.1 s]                          \n",
      "Epoch 25    loss=0.2941 [258.3 s]\tdev=(HR@5:0.4489,NDCG@5:0.3540) [20.1 s]                          \n",
      "Epoch 26 :  39%|███████████████████▎                              | 324/838 [01:31<02:27,  3.50it/s]^C\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fefd9ef6160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/wang/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1441, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Early stop manually                                                                                 \n",
      "Exit completely without evaluation? (y/n) (default n):\n",
      "Best Iter(dev)=   21\t dev=(HR@5:0.4546,NDCG@5:0.3568) [6324.2 s] \n",
      "/mnt/e/collegeitem/third1/machinelearning/Fuxi-alpha-in-ReChorus/ReChorus/src/models/BaseModel.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "!python src/main.py $COMMON_ML1M_L200 \\\n",
    "  --model_name fuxi_upgrade \\\n",
    "  --model_path {model_path} \\\n",
    "  --log_file {log_file} \\\n",
    "  --fuxi_blocks  8\\\n",
    "  --fuxi_heads 2 \\\n",
    "  --fuxi_attention_dim 25 \\\n",
    "  --fuxi_linear_dim 25 \\\n",
    "  --save_final_results 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
